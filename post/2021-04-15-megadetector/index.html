<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    <meta property="og:site_name" content="David D. Hofmann">
    <meta property="og:type" content="article">

    
    <meta property="og:image" content="https://daviddhofmann.github.io//img/campanula.JPG">
    <meta property="twitter:image" content="https://daviddhofmann.github.io//img/campanula.JPG" />
    

    
    <meta name="title" content="Using Microsoft&#39;s MegaDetector to Detect Animals on Cameratrap Images" />
    <meta property="og:title" content="Using Microsoft&#39;s MegaDetector to Detect Animals on Cameratrap Images" />
    <meta property="twitter:title" content="Using Microsoft&#39;s MegaDetector to Detect Animals on Cameratrap Images" />
    

    
    <meta name="description" content="David D. Hofmann&#39;s Personal Website">
    <meta property="og:description" content="David D. Hofmann&#39;s Personal Website" />
    <meta property="twitter:description" content="David D. Hofmann&#39;s Personal Website" />
    

    
    <meta property="twitter:card" content="Camera trap studies usually deal with thousands of camera trap images that have to be organized and sorted. In this blog-post, I&#39;m going to illustrate how you can use Microsoft&#39;s MegaDetector to automatically detect animals in camera trap images. This can be very useful to automate the identification and removal of images that do not contain any animals." />
    
    

    <meta name="keyword"  content="David Hofmann, Blog, PhD Student, Ecology, University of Zurich, R, Movement Ecology, Botany">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>Using Microsoft&#39;s MegaDetector to Detect Animals on Cameratrap Images-David D. Hofmann | UZH</title>

    <link rel="canonical" href="/post/2021-04-15-megadetector/">

    <link rel="stylesheet" href="/css/iDisqus.min.css"/>
	
    
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    
    <link rel="stylesheet" href="/css/hux-blog.min.css">

    
    <link rel="stylesheet" href="/css/zanshang.css">
    
    
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    
    

    
    
    <script src="/js/jquery.min.js"></script>
    
    
    <script src="/js/bootstrap.min.js"></script>
    
    
    <script src="/js/hux-blog.min.js"></script>

    
    

</head>



<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">David D. Hofmann</a>
        </div>

        
        
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    
                    
		    
                        <li><a href="/top/about/">ABOUT</a></li>
                    
                        <li><a href="/">BLOG</a></li>
                    
                        <li><a href="/top/gallery/">GALLERY</a></li>
                    

                    
                </ul>
            </div>
        </div>
        
    </div>
    
</nav>
<script>
    
    
    
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        
            $navbar.className = " ";
            
            setTimeout(function(){
                
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>




<style type="text/css">
    header.intro-header {
        background-image: url('/img/post_megadetector.jpg')
    }
</style>
<header class="intro-header">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/r" title="R">
                            R
                        </a>
                        
                        <a class="tag" href="/tags/deep-learning" title="deep learning">
                            deep learning
                        </a>
                        
                        <a class="tag" href="/tags/cameratrap" title="cameratrap">
                            cameratrap
                        </a>
                        
                        <a class="tag" href="/tags/megadetector" title="megadetector">
                            megadetector
                        </a>
                        
                    </div>
                    <h1>Using Microsoft&#39;s MegaDetector to Detect Animals on Cameratrap Images</h1>
                    <h2 class="subheading"></h2>
                    <span class="meta">
                        Posted by 
                        
                            David D. Hofmann
                         
                        on 
                        Thursday, April 15, 2021
                        
                        
                        
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>




<article>
    <div class="container">
        <div class="row">

            
            <div class="
                col-lg-11 col-lg-offset-1
                col-md-10 col-md-offset-1
                post-container">

                
                <header>
                    <h2>TOC</h2>
                </header>
                
                
                
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<script src="/rmarkdown-libs/accessible-code-block/empty-anchor.js"></script>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#installation">Installation</a>
<ul>
<li><a href="#installing-python">Installing Python</a></li>
<li><a href="#installing-tensorflow-and-other-python-packages">Installing Tensorflow and Other Python Packages</a></li>
<li><a href="#downloading-additional-files-from-github">Downloading Additional Files from Github</a></li>
<li><a href="#making-the-downloaded-files-available-to-python">Making the Downloaded Files Available to Python</a></li>
<li><a href="#a-brief-overview-of-the-downloaded-files">A Brief Overview of the Downloaded Files</a></li>
</ul></li>
<li><a href="#running-the-megadetector">Running the MegaDetector</a>
<ul>
<li><a href="#approach-i">Approach I</a></li>
<li><a href="#approach-ii">Approach II</a></li>
</ul></li>
<li><a href="#processing-the-megadetector-output">Processing the MegaDetector Output</a></li>
<li><a href="#summary">Summary</a></li>
<li><a href="#session-information">Session Information</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Wildlife cameras (Figure 1) have become an increasingly popular tool to monitor
and study animal populations. One of the main reason why cameras have become so
omnipresent in ecology is because they are non-invasive and, once set up, can be
left in the field for months with only little maintenance. This allows for a
laregly automated collection of images that grant exciting insights into
wildlife. On the downside, wildlife cameras often produce thousands of images
that all need to be screened by trained biologists to identify the animals on
each image. This can be very time-consuiming and cumbersome, particularly if
many of the images are empty and do not contain any animals (so called false
positives). Consequently, there has been growing interests towards automating
these tedious processes with the aid of computers.</p>
<div class="figure"><span id="fig:unnamed-chunk-1"></span>
<img src="/img/gallery_megadetector/figure1.jpg" alt="A Brownings wildlife camera that I've set up in my garden to learn about our nocturnal visitors from the nearby forest." width="50%" />
<p class="caption">
Figure 1: A Brownings wildlife camera that I’ve set up in my garden to learn about our nocturnal visitors from the nearby forest.
</p>
</div>
<p>With the uprise of deep learning techniques, such tasks can now finally be
tackled efficiently using computer vision. For cameratrap images in particular,
Microsoft has recently released a neural network called the “MegaDetector”. The
MegaDetector is a powerful neural network that has been trained to distinguish
the categories “humans”, “vehicles”, and “animals” on any kind of image. To
learn about those categories, it has been exposed to millions of images with
known detections and known absences of those categories. Ultimately, the
computer itself learned how to detect humans, vehicles, and animals on images.
Even though the detector only detects these three categories, it does so with
great reliability. Consequently, the MegaDetector may serve as a first filter to
remove empty images, thereby reducing the amount of images that need to be
visually inspected by a human being. In this blog-post, I will to outline a
simple workflow that allows you to apply the MegaDetector on your own set of
images. Finally, we will make use of the output file generated by the
MegaDetector to visualize a set of images with bounding boxes around the
different detections in each image.</p>
</div>
<div id="installation" class="section level1">
<h1>Installation</h1>
<p>Probably the most difficult part of using the MegaDetector is to set everything
up and running. Hence, I will try to be as thorough as I can and explain each
step in as much detail as possible. Nevertheless, I may refer to other sources
in some cases. Also note that much of this blog post has been inspired by
<a href="https://github.com/microsoft/CameraTraps/blob/master/megadetector.md#using-the-models">Microsoft’s Github
Instructions</a>
which contains all the basic information on using the <em>MegaDetector</em>.</p>
<div id="installing-python" class="section level2">
<h2>Installing Python</h2>
<p>In order to use the MegaDetector, you need to have python installed on your
computer. Some computers already have a system installation of python, yet I
would still highly recommend that you install python using
<a href="https://docs.conda.io/en/latest/miniconda.html">conda</a>. Conda is a really
accessible package and environment manager that allows you to easily create
virtual environments containing python and packages of a desired version. This
drastically reduces the need to manually fiddle with different versions of
different packages and enables you to test your nasty python scripts in a save
environment. Depending on your operating system the installation of conda
differs, hence I suggest that you check out the specific installation
instructions here:</p>
<ul>
<li><a href="https://conda.io/projects/conda/en/latest/user-guide/install/windows.html">Windows</a></li>
<li><a href="https://conda.io/projects/conda/en/latest/user-guide/install/macos.html">MacOS</a></li>
<li><a href="https://conda.io/projects/conda/en/latest/user-guide/install/linux.html#">Linux</a></li>
</ul>
<p>Once you have installed conda, open up a new terminal. If conda installed
correctly, you should now see an indicator telling you that conda booted into
the <em>base</em> environment.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># In brackets, conda always tells you in which environment you are working</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="kw">(</span><span class="ex">base</span><span class="kw">)</span> <span class="ex">david@minty</span>:~$</span></code></pre></div>
<p>With conda, it is now very easy to create a new python environment. In fact, we
are going to create a new environment called <em>cameratrapping</em> that uses python
version 3.6. To do so, we run the following command:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># Create new virtual environment that runs python version 3.6</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="ex">conda</span> create -n cameratrapping python=3.6</span></code></pre></div>
<p>Note that we specifically tell conda to use python version 3.6. This is
extremely important as some of the packages we’ll be using do not work with more
up to date versions of python. However, thanks to conda it is rather easy to
install different python versions. Anyways, once you successfully setup the new
environment, you still need to switch into it. This can be done by “activating”
the new environemnt:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># Switch to the new environment</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="ex">conda</span> activate cameratrapping</span></code></pre></div>
<p>After activation, you’re terminal should indicate that conda switched to the
<em>cameratrapping</em> environment, meaning that you left the base environment and are
now working in the cameratrapping environment (which runs python version 3.6).</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># Conda should have switched to the &quot;cameratrapping&quot; environment now</span></span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="kw">(</span><span class="ex">cameratrapping</span><span class="kw">)</span> <span class="ex">david@minty</span>:~$</span></code></pre></div>
<p>With <code>activate environment-name</code> you can always go back and forth between
different environments depending on your needs. To get a list of all
environments, simply call:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1"></a><span class="co"># Show all available environments</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="ex">conda</span> env list</span></code></pre></div>
</div>
<div id="installing-tensorflow-and-other-python-packages" class="section level2">
<h2>Installing Tensorflow and Other Python Packages</h2>
<p>To be able to run the <em>MegaDetector</em>, we’ll need to install tensorflow version
1.13.1. This is a rather old version and also the reason why we had to opt for
python version 3.6. To install the specific version of tensorflow, first make
sure that you are working in the <em>cameratrapping</em> environment, then use <em>pip</em>
to install tensorflow version 1.13.1:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1"></a><span class="co"># Install tensorflow</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="ex">pip</span> install tensorflow==1.13.1</span></code></pre></div>
<p>In case your computer has a dedicated gpu, you may also run the megadetector on
the gpu. In this case, you would need to install tensorflow slightly
differently:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># Install tensorflow-gpu (using conda instead of pip)</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="ex">conda</span> install -c anaconda tensorflow-gpu=1.13.1</span></code></pre></div>
<p>Besides tensorflow, we also need to install several other python packages.
However, here the exact versions do not really matter and we can thus install
all of them as follows:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1"></a><span class="co"># Install other dependencies</span></span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="ex">pip</span> install pillow humanfriendly matplotlib tqdm jsonpickle statistics requests</span></code></pre></div>
</div>
<div id="downloading-additional-files-from-github" class="section level2">
<h2>Downloading Additional Files from Github</h2>
<p>In addition to the above installed python packages, we also need to download
some folders and files that provide further functionalities. I would recommend
that you download the files into a distinct folder called <em>CameraTrapping</em>. If
you are familiar with git and have it installed on your computer, you can
download the required files using git (see Option 1). Oterhwise, just download
them manually (see Option 2).</p>
<div id="option-1-using-git" class="section level3">
<h3>Option 1: Using Git</h3>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># Change directory (cd) into the &quot;CameraTrapping&quot; folder. The exact path will be</span></span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="co"># different for you!</span></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="bu">cd</span> /home/david/Schreibtisch/CameraTrapping</span>
<span id="cb9-4"><a href="#cb9-4"></a></span>
<span id="cb9-5"><a href="#cb9-5"></a><span class="co"># Download required files and folders from GitHub</span></span>
<span id="cb9-6"><a href="#cb9-6"></a><span class="fu">git</span> clone https://github.com/Microsoft/cameratraps</span>
<span id="cb9-7"><a href="#cb9-7"></a><span class="fu">git</span> clone https://github.com/Microsoft/ai4eutils</span>
<span id="cb9-8"><a href="#cb9-8"></a><span class="fu">wget</span> https://raw.githubusercontent.com/microsoft/CameraTraps/master/detection/run_tf_detector.py</span>
<span id="cb9-9"><a href="#cb9-9"></a><span class="fu">wget</span> https://raw.githubusercontent.com/microsoft/CameraTraps/master/detection/run_tf_detector_batch.py</span>
<span id="cb9-10"><a href="#cb9-10"></a><span class="fu">wget</span> https://lilablobssc.blob.core.windows.net/models/camera_traps/megadetector/md_v4.1.0/md_v4.1.0.pb</span>
<span id="cb9-11"><a href="#cb9-11"></a></span>
<span id="cb9-12"><a href="#cb9-12"></a><span class="co"># OPTIONAL: Download example images</span></span>
<span id="cb9-13"><a href="#cb9-13"></a><span class="fu">git</span> clone https://github.com/DavidDHofmann/sample_images</span></code></pre></div>
</div>
<div id="option-2-manual-download" class="section level3">
<h3>Option 2: Manual Download</h3>
<p>You can manually download the files from the links below. Store all of the files
and folders into a distinct folder called <em>CameraTrapping</em> and make sure their
names are similar to those highlighted in blue.</p>
<ul>
<li><p><a href="https://github.com/Microsoft/cameratraps">cameratraps</a> (Github Repository / Folder)</p></li>
<li><p><a href="https://github.com/Microsoft/ai4eutils">ai4eutils</a> (Github Repository / Folder)</p></li>
<li><p><a href="https://github.com/Microsoft/CameraTraps/blob/master/detection/run_tf_detector.py">run_tf_detector.py</a> (Python Script)</p></li>
<li><p><a href="https://github.com/microsoft/CameraTraps/blob/master/run_tf_detector_batch.py">run_tf_detector_batch.py</a> (Python Script)</p></li>
<li><p><a href="https://lilablobssc.blob.core.windows.net/models/camera_traps/megadetector/md_v4.1.0/md_v4.1.0.pb">md_v4.1.0.pb</a> (Model File)</p></li>
<li><p><a href="https://github.com/DavidDHofmann/sample_images">sample_images</a> (Some sample camertrap images that I recorded in my garden)</p></li>
</ul>
</div>
</div>
<div id="making-the-downloaded-files-available-to-python" class="section level2">
<h2>Making the Downloaded Files Available to Python</h2>
<p>Finally, we need to make sure that the downloaded folders “ai4eutils” and
“cameratraps” can be found by python. To ensure this, we can run the commands
below. Note that you will need to execute this code everytime you start a new
session in the respective environemnt.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># Make folders available to python</span></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="bu">export</span> <span class="va">PYTHONPATH=</span><span class="st">&quot;</span><span class="va">$PYTHONPATH</span><span class="st">:</span><span class="va">$PWD</span><span class="st">/ai4eutils:</span><span class="va">$PWD</span><span class="st">/cameratraps&quot;</span></span></code></pre></div>
</div>
<div id="a-brief-overview-of-the-downloaded-files" class="section level2">
<h2>A Brief Overview of the Downloaded Files</h2>
<p>If everything worked fine, your <em>CameraTrapping</em> folder should now have the
following structure.</p>
<pre><code>CameraTrapping
└───ai4eutils
    └───...
└───cameratraps
    └───...
└───sample_images
    │ L002_R01_20210307212248.JPG
    │ L002_R01_20210308022921.JPG
    │ ...
    └───detections
│   md_v4.1.0.pb
│   run_tf_detector.py
│   run_tf_detector_batch.py</code></pre>
<p>Let me briefly explain what each of these elements are used for. The first two
elements (<em>ai4utils</em> and <em>cameratraps</em>) are simply two folders that contain some
tools that the <em>MegaDetector</em> needs. We don’t need to worry about those much.
The folder <em>sample_images</em> contains several example images from camera traps
that I collected in my (girlfriend’s) garden. We can use those to test if the
<em>MegaDetector</em> actually works. The <em>md_v4.1.0.pb</em> file contains the
MegaDetector. You can think of this as the “brain” of our little operation and
is the “brain” of the detection algorithm. Furthermore, there are two python
scripts (.py). These serve as interface and allow us to initiate the
<em>MegaDetector</em> through the terminal/command line. The first script
(<em>run_tf_detector.py</em>) is intended for testing only and serves to quickly
generate and visualize some detections. It basically allows us to take an input
image and to return another image highlighting the detected objects. The second
script (<em>run_tf_detector_batch.py</em>) runs detections in batches and periodically
saves the results. While it does not create neat looking images showing the
different detections, it outputs a .json file that lists all detections in a
structured way. This is usually the script you’ll use when you want to make
detections on a large batch of images.</p>
</div>
</div>
<div id="running-the-megadetector" class="section level1">
<h1>Running the MegaDetector</h1>
<p>As stated above, there are two different ways in which we can run the
MegaDetector:</p>
<ul>
<li><p>Approach No. 1: We use the <em>run_tf_detector.py</em> script, which automatically
runs the detection algorithm and returns one or multiple images on which
bounding boxes around all detections are drawn. This approach is more suitable
for testing and for small sets of images if you only want to quickly visualize
some detections. However, for more scientific purposes it is not very useful
because the detection information is not stored in a structured manner and can’t
be accessed or used for further analysis.</p></li>
<li><p>Approach No. 2: We use the <em>run_tf_detector_batch.py</em> script which runs the
detection algorithm and returns a “list of lists” containing all detections.
Conveniently, each detection has an associated uncertainty, showing us how
“confident” the detector is for that specific detection. While this approach
does not directly produce images with neat bounding boxes, it is much more
useful for scientific purposes, as we can easily use the returned file for
further analysis and subsetting of the different images. In addition, this
script periodically saves the MegaDetector’s so that not all is lost in case
your computer crashes when running the detection on a large set of images.</p></li>
</ul>
<p>Regardless of your preferred method, you should now double-check that everything
is setup correctly and that your terminal points to the correct directory (i.e.
that you’re working within the <em>Cameratrapping</em> folder and that you are using
the <em>cameratrapping</em> conda environment). Alright, if this is done, let’s run
some detections.</p>
<div id="approach-i" class="section level2">
<h2>Approach I</h2>
<p>In this first approach, we use the <em>run_tf_detector.py</em> script and run it from
our computer terminal. The script can either be applied to a single image or to
an entire directory, meaning that it will go through each image in the provided
directory. Let’s first take a look at the anatomy of the commands that we’ll be
using. The commands to invoke the python script are the following (you’ll need
to fill in <em>filename</em> and <em>directoryname</em> by yourself):</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1"></a><span class="co"># If you want to run the detection on a single image</span></span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="ex">python</span> run_tf_detector.py md_v4.1.0.pb --input_file filename --output_dir directoryname</span>
<span id="cb12-3"><a href="#cb12-3"></a></span>
<span id="cb12-4"><a href="#cb12-4"></a><span class="co"># If you want to run the detection on an entire directory</span></span>
<span id="cb12-5"><a href="#cb12-5"></a><span class="ex">python</span> run_tf_detector.py md_v4.1.0.pb --input_dir directoryname --output_dir directoryname</span></code></pre></div>
<p>Let me briefly explain what each element of these commands are doing:</p>
<ul>
<li><p><code>python run_tf_detector.py</code> tells our computer to run the run_tf_detector.py
script using python.</p></li>
<li><p><code>md_v4.1.0.pb</code> is our model file (i.e. the pre-trained neural
network).</p></li>
<li><p><code>--input_file filename</code> allows us to specify the image on which we want to
detect images</p></li>
<li><p><code>--input_dir directoryname</code> allows us to specify the directory containing all
images on which we want to detect animals</p></li>
<li><p><code>--output_dir directoryname</code> allows us to specify the directory into which the
newly created images should be stored</p></li>
</ul>
<p>Of course there are many other options that you may want to play with. However,
this goes beyond the scope of this introduction. To get the full list of
available options, simply type:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1"></a><span class="co"># Show available options</span></span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="ex">python</span> run_tf_detector.py -h</span></code></pre></div>
<p>Anyways, let’s run the detector on some real images. In case you have downloaded
my example images, the commands from above translate into:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1"></a><span class="co"># Run MegaDetector on a single image</span></span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="ex">python</span> run_tf_detector.py md_v4.1.0.pb --image_file sample_images/L002_R01_20210314013742.JPG --output_dir sample_images/detections</span>
<span id="cb14-3"><a href="#cb14-3"></a></span>
<span id="cb14-4"><a href="#cb14-4"></a><span class="co"># Run MegaDetector on an entire directory</span></span>
<span id="cb14-5"><a href="#cb14-5"></a><span class="ex">python</span> run_tf_detector.py md_v4.1.0.pb --image_dir sample_images --output_dir sample_images/detections</span></code></pre></div>
<p>If everything is setup correctly, the <em>MegaDetector</em> will get to work and run
the detections for you. Once the algorithm terminates, you can go to the
<em>sample_images/detections</em> folder where you should find the final images with
bounding boxes around each detected animal/human/vehicle. The images should look
something like shown in Figure 3b).</p>
<div class="figure"><span id="fig:unnamed-chunk-15"></span>
<img src="/img/gallery_megadetector/figure2.png" alt="a) Input image and b) output image produced by the run_tf_detector.py script." width="100%" />
<p class="caption">
Figure 2: a) Input image and b) output image produced by the run_tf_detector.py script.
</p>
</div>
<p>Nice! We just ran our first detection. Now let’s see how we can expand this to a
more extensive dataset.</p>
</div>
<div id="approach-ii" class="section level2">
<h2>Approach II</h2>
<p>In this approach, we use the <em>run_tf_batch_detector.py</em> script. While this
script does not generate neat looking pictures with bounding boxes, it creates a
<em>.json</em> file that contains all the detections in a structured format. This
allows us to import the file into R for further analysis. Again, let’s first
look at the anatomy of the invoked command. To invoke the batch-detector script,
we can use the following code (you’ll need to fill in <em>filename/directory</em> and
<em>filename.json</em> by yourself):</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1"></a><span class="co"># To run the MegaDetector batch file</span></span>
<span id="cb15-2"><a href="#cb15-2"></a><span class="ex">python</span> run_tf_detector_batch.py md_v4.1.0.pb --input_file filename/directory --output_file filename.json</span></code></pre></div>
<p>Again, we want to know what each piece of the code is doing.</p>
<ul>
<li><p><code>python run_tf_detector_batch.py</code> tells our computer to run the
run_tf_detector_batch.py script using python.</p></li>
<li><p><code>md_v4.1.0.pb</code> is the <em>MegaDetector</em> model file (i.e. the pre-trained neural
network).</p></li>
<li><p><code>--input_file filename/directory</code> allows us to specify the image or a
directory for which we’d like to run the algorithm</p></li>
<li><p><code>--output_file filename.json</code> allows us to specify the directory into which
the .json file shoud be stored</p></li>
</ul>
<p>Pretty simple ey? For our sample images, this code snippet translates into:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1"></a><span class="co"># Run the MegaDetector and create a .json file</span></span>
<span id="cb16-2"><a href="#cb16-2"></a><span class="ex">python</span> run_tf_detector_batch.py md_v4.1.0.pb /home/david/Schreibtisch/CameraTrapping/sample_images /home/david/Schreibtisch/CameraTrapping/sample_images/detections/detections.json</span></code></pre></div>
<p>Again, the MegaDetector should get to work and start detecting animals.
Depending on your computer and the number of images, this will take a while to
complete, but luckily the MegaDetector gives you detailed information about its
progress while its running.</p>
</div>
</div>
<div id="processing-the-megadetector-output" class="section level1">
<h1>Processing the MegaDetector Output</h1>
<p>In case you run the <em>run_tf_detector_batch.py</em>, you’ll end up with a .json file
containing all detections. You can of course open the file in a text-editor and
try to go through the detections by hand. However, I strongly recommend to
further process the file. Here, we will use R to import and clean the file and
to visualize some of the detections. To load the file, we can use the
<code>fromJSON()</code> function from the <code>rjson</code> package.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a><span class="co"># Load required packages</span></span>
<span id="cb17-2"><a href="#cb17-2"></a><span class="kw">library</span>(rjson)      <span class="co"># To read a json file</span></span>
<span id="cb17-3"><a href="#cb17-3"></a><span class="kw">library</span>(tidyverse)  <span class="co"># For data wrangling</span></span>
<span id="cb17-4"><a href="#cb17-4"></a><span class="kw">library</span>(exifr)      <span class="co"># To read image meta-data</span></span>
<span id="cb17-5"><a href="#cb17-5"></a><span class="kw">library</span>(magick)     <span class="co"># To plot images</span></span>
<span id="cb17-6"><a href="#cb17-6"></a><span class="kw">library</span>(lubridate)  <span class="co"># To handle timestamps</span></span>
<span id="cb17-7"><a href="#cb17-7"></a></span>
<span id="cb17-8"><a href="#cb17-8"></a><span class="co"># Set working directory (this will be different for you)</span></span>
<span id="cb17-9"><a href="#cb17-9"></a><span class="kw">setwd</span>(<span class="st">&quot;/home/david/Schreibtisch/CameraTrapping/sample_images&quot;</span>)</span>
<span id="cb17-10"><a href="#cb17-10"></a></span>
<span id="cb17-11"><a href="#cb17-11"></a><span class="co"># Load json file produced by the MegaDetector</span></span>
<span id="cb17-12"><a href="#cb17-12"></a>anot &lt;-<span class="st"> </span><span class="kw">fromJSON</span>(<span class="dt">file =</span> <span class="st">&quot;detections/detections.json&quot;</span>)</span></code></pre></div>
<p>Once the .json-file has been loaded, let’s take a look at its’ structure.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a><span class="co"># Look at the structure of the json file</span></span>
<span id="cb18-2"><a href="#cb18-2"></a><span class="kw">str</span>(anot, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## List of 3
##  $ images              :List of 10
##   ..$ :List of 3
##   ..$ :List of 3
##   ..$ :List of 3
##   ..$ :List of 3
##   ..$ :List of 3
##   ..$ :List of 3
##   ..$ :List of 3
##   ..$ :List of 3
##   ..$ :List of 3
##   ..$ :List of 3
##  $ detection_categories:List of 3
##   ..$ 1: chr &quot;animal&quot;
##   ..$ 2: chr &quot;person&quot;
##   ..$ 3: chr &quot;vehicle&quot;
##  $ info                :List of 2
##   ..$ detection_completion_time: chr &quot;2021-04-13 11:51:52&quot;
##   ..$ format_version           : chr &quot;1.0&quot;</code></pre>
<p>The file is basically a list of lists containing lots of information on the
original input images, detected categories, and on the algorithm itself. We can
consolidate all of this information into a single tibble/dataframe that is
easier to read:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a><span class="co"># Extract detected categories and put them into a tibble/dataframe</span></span>
<span id="cb20-2"><a href="#cb20-2"></a>cats              &lt;-<span class="st"> </span><span class="kw">enframe</span>(anot<span class="op">$</span>detection_categories)</span>
<span id="cb20-3"><a href="#cb20-3"></a><span class="kw">names</span>(cats)       &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;CategoryID&quot;</span>, <span class="st">&quot;CategoryName&quot;</span>)</span>
<span id="cb20-4"><a href="#cb20-4"></a>cats<span class="op">$</span>CategoryName &lt;-<span class="st"> </span><span class="kw">unlist</span>(cats<span class="op">$</span>CategoryName)</span>
<span id="cb20-5"><a href="#cb20-5"></a></span>
<span id="cb20-6"><a href="#cb20-6"></a><span class="co"># Get information into nice format</span></span>
<span id="cb20-7"><a href="#cb20-7"></a>info &lt;-<span class="st"> </span><span class="kw">tibble</span>(</span>
<span id="cb20-8"><a href="#cb20-8"></a>      <span class="dt">images     =</span> <span class="kw">map_chr</span>(anot<span class="op">$</span>images, <span class="st">&quot;file&quot;</span>)</span>
<span id="cb20-9"><a href="#cb20-9"></a>    , <span class="dt">detections =</span> <span class="kw">lapply</span>(anot<span class="op">$</span>images, <span class="cf">function</span>(x){</span>
<span id="cb20-10"><a href="#cb20-10"></a>      <span class="kw">tibble</span>(</span>
<span id="cb20-11"><a href="#cb20-11"></a>          <span class="dt">category   =</span> <span class="kw">map_chr</span>(x<span class="op">$</span>detections, <span class="st">&quot;category&quot;</span>)</span>
<span id="cb20-12"><a href="#cb20-12"></a>        , <span class="dt">confidence =</span> <span class="kw">map_dbl</span>(x<span class="op">$</span>detections, <span class="st">&quot;conf&quot;</span>)</span>
<span id="cb20-13"><a href="#cb20-13"></a>        , <span class="dt">bbox       =</span> <span class="kw">map</span>(x<span class="op">$</span>detections, <span class="st">&quot;bbox&quot;</span>)</span>
<span id="cb20-14"><a href="#cb20-14"></a>      )</span>
<span id="cb20-15"><a href="#cb20-15"></a>    })</span>
<span id="cb20-16"><a href="#cb20-16"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb20-17"><a href="#cb20-17"></a><span class="st">  </span><span class="kw">unnest</span>(detections) <span class="op">%&gt;%</span></span>
<span id="cb20-18"><a href="#cb20-18"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">bbox =</span> <span class="kw">map</span>(bbox, <span class="cf">function</span>(x){<span class="kw">paste0</span>(x, <span class="dt">collapse =</span> <span class="st">&quot;, &quot;</span>)})) <span class="op">%&gt;%</span></span>
<span id="cb20-19"><a href="#cb20-19"></a><span class="st">  </span><span class="kw">separate</span>(bbox</span>
<span id="cb20-20"><a href="#cb20-20"></a>    , <span class="dt">sep     =</span> <span class="st">&quot;,&quot;</span></span>
<span id="cb20-21"><a href="#cb20-21"></a>    , <span class="dt">into    =</span> <span class="kw">c</span>(<span class="st">&quot;x_left&quot;</span>, <span class="st">&quot;y_top&quot;</span>, <span class="st">&quot;x_width&quot;</span>, <span class="st">&quot;y_height&quot;</span>)</span>
<span id="cb20-22"><a href="#cb20-22"></a>    , <span class="dt">convert =</span> T</span>
<span id="cb20-23"><a href="#cb20-23"></a>  )</span>
<span id="cb20-24"><a href="#cb20-24"></a></span>
<span id="cb20-25"><a href="#cb20-25"></a><span class="co"># Join categories to the info table</span></span>
<span id="cb20-26"><a href="#cb20-26"></a>info &lt;-<span class="st"> </span><span class="kw">left_join</span>(info, cats, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;category&quot;</span> =<span class="st"> &quot;CategoryID&quot;</span>))</span>
<span id="cb20-27"><a href="#cb20-27"></a></span>
<span id="cb20-28"><a href="#cb20-28"></a><span class="co"># Look at the generated dataframe</span></span>
<span id="cb20-29"><a href="#cb20-29"></a><span class="kw">head</span>(info)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 8
##   images          category confidence x_left y_top x_width y_height CategoryName
##   &lt;chr&gt;           &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       
## 1 /home/david/Sc… 1             0.999  0.353 0.327   0.269    0.290 animal      
## 2 /home/david/Sc… 1             0.999  0.377 0.320   0.101    0.107 animal      
## 3 /home/david/Sc… 1             0.999  0.695 0.511   0.279    0.450 animal      
## 4 /home/david/Sc… 1             0.999  0.438 0.383   0.196    0.193 animal      
## 5 /home/david/Sc… 2             0.999  0.361 0       0.155    0.461 person      
## 6 /home/david/Sc… 1             0.994  0     0.434   0.240    0.304 animal</code></pre>
<p>Awesome! Take a look at the output from the cleaned dataframe. It contains a row
for each detection, so that if one image contains more than one detection, there
will be multiple rows for the same image. By looking at the columns, we see that
the file contains information on the detected categories (<em>cateogry</em> &amp;
<em>CategoryName</em>) and on the bounding boxes surrounding each of the detections.
The bounding boxes are defined by an x and y coordinate (<em>x_left</em> &amp; <em>y_top</em>) and
a width and a height (<em>x_width</em> &amp; <em>y_height</em>). Note that the respective numbers
are given on a scale from 0 to 1, so that we’ll need to adjust the values
depending on the image resolution. It is also important to note that in computer
vision the y axis starts at the top and not from the bottom. Besides information
on the detected category and the associated bounding box, we also see that for
each detection the detector returned a measure of confidence (<em>confidence</em>).
This is really useful because it allows us to subset to detections that exceed a
desired threshold!</p>
<p>Now that we compiled all information into a nice table, we can conduct a wide
range of exploratory analyses. For instance, we may want to identify all images
on which the detector identified an animal with a relatively high confidence. We
can easily subset to those images as follows:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1"></a><span class="co"># Identify images that contain animals</span></span>
<span id="cb22-2"><a href="#cb22-2"></a>info <span class="op">%&gt;%</span></span>
<span id="cb22-3"><a href="#cb22-3"></a><span class="st">  </span><span class="kw">subset</span>(CategoryName <span class="op">==</span><span class="st"> &quot;animal&quot;</span> <span class="op">&amp;</span><span class="st"> </span>confidence <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.9</span>)</span></code></pre></div>
<pre><code>## # A tibble: 8 x 8
##   images          category confidence x_left y_top x_width y_height CategoryName
##   &lt;chr&gt;           &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       
## 1 /home/david/Sc… 1             0.999  0.353 0.327  0.269    0.290  animal      
## 2 /home/david/Sc… 1             0.999  0.377 0.320  0.101    0.107  animal      
## 3 /home/david/Sc… 1             0.999  0.695 0.511  0.279    0.450  animal      
## 4 /home/david/Sc… 1             0.999  0.438 0.383  0.196    0.193  animal      
## 5 /home/david/Sc… 1             0.994  0     0.434  0.240    0.304  animal      
## 6 /home/david/Sc… 1             0.998  0.556 0.381  0.223    0.404  animal      
## 7 /home/david/Sc… 1             0.937  0.278 0.501  0.0474   0.0675 animal      
## 8 /home/david/Sc… 1             0.999  0.489 0.532  0.0701   0.122  animal</code></pre>
<p>By default, the MegaDetector also returns detections for which he is very
uncertain, which you can see by plotting a histogram of the “Confidence” values.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1"></a><span class="co"># Histogram of MegaDetectors confidence</span></span>
<span id="cb24-2"><a href="#cb24-2"></a><span class="kw">hist</span>(info<span class="op">$</span>confidence</span>
<span id="cb24-3"><a href="#cb24-3"></a>  , <span class="dt">breaks =</span> <span class="dv">10</span></span>
<span id="cb24-4"><a href="#cb24-4"></a>  , <span class="dt">main   =</span> <span class="st">&quot;Histogram of Confidence&quot;</span></span>
<span id="cb24-5"><a href="#cb24-5"></a>  , <span class="dt">xlab   =</span> <span class="st">&quot;Confidence&quot;</span></span>
<span id="cb24-6"><a href="#cb24-6"></a>  , <span class="dt">ylab   =</span> <span class="st">&quot;Frequency&quot;</span></span>
<span id="cb24-7"><a href="#cb24-7"></a>  , <span class="dt">col    =</span> <span class="st">&quot;cornflowerblue&quot;</span></span>
<span id="cb24-8"><a href="#cb24-8"></a>  , <span class="dt">border =</span> <span class="ot">NA</span></span>
<span id="cb24-9"><a href="#cb24-9"></a>)</span></code></pre></div>
<p><img src="/post/2021-04-15-megadetector_files/figure-html/unnamed-chunk-22-1.png" width="50%" /></p>
<p>For now, we only want to consider detections with relatively high confidence. So
let’s subset the data accordingly.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1"></a><span class="co"># Subset to detections with high confidence</span></span>
<span id="cb25-2"><a href="#cb25-2"></a>info &lt;-<span class="st"> </span>info <span class="op">%&gt;%</span></span>
<span id="cb25-3"><a href="#cb25-3"></a><span class="st">  </span><span class="kw">subset</span>(confidence <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.9</span>)</span></code></pre></div>
<p>You may also be interested during which time of the day you detected most
animals. For this, we have to extract the timestamp of each cameratrap image. We
can use the function <code>read_exif()</code> from the <code>exifr</code> package to extract such
information from the image metadata. In fact, the function returns and entire
dataframe of really useful information on each image that we may want to store
for later.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1"></a><span class="co"># Load image metadata</span></span>
<span id="cb26-2"><a href="#cb26-2"></a>meta &lt;-<span class="st"> </span><span class="kw">read_exif</span>(info<span class="op">$</span>images)</span>
<span id="cb26-3"><a href="#cb26-3"></a></span>
<span id="cb26-4"><a href="#cb26-4"></a><span class="co"># This contains a ton of information!</span></span>
<span id="cb26-5"><a href="#cb26-5"></a><span class="kw">names</span>(meta)</span></code></pre></div>
<pre><code>##  [1] &quot;SourceFile&quot;                 &quot;ExifToolVersion&quot;           
##  [3] &quot;FileName&quot;                   &quot;Directory&quot;                 
##  [5] &quot;FileSize&quot;                   &quot;FileModifyDate&quot;            
##  [7] &quot;FileAccessDate&quot;             &quot;FileInodeChangeDate&quot;       
##  [9] &quot;FilePermissions&quot;            &quot;FileType&quot;                  
## [11] &quot;FileTypeExtension&quot;          &quot;MIMEType&quot;                  
## [13] &quot;ExifByteOrder&quot;              &quot;ImageDescription&quot;          
## [15] &quot;Make&quot;                       &quot;Model&quot;                     
## [17] &quot;Orientation&quot;                &quot;XResolution&quot;               
## [19] &quot;YResolution&quot;                &quot;ResolutionUnit&quot;            
## [21] &quot;Software&quot;                   &quot;ModifyDate&quot;                
## [23] &quot;YCbCrPositioning&quot;           &quot;Copyright&quot;                 
## [25] &quot;ExposureTime&quot;               &quot;FNumber&quot;                   
## [27] &quot;ExposureProgram&quot;            &quot;ISO&quot;                       
## [29] &quot;ExifVersion&quot;                &quot;DateTimeOriginal&quot;          
## [31] &quot;CreateDate&quot;                 &quot;ComponentsConfiguration&quot;   
## [33] &quot;CompressedBitsPerPixel&quot;     &quot;ShutterSpeedValue&quot;         
## [35] &quot;ApertureValue&quot;              &quot;ExposureCompensation&quot;      
## [37] &quot;MaxApertureValue&quot;           &quot;MeteringMode&quot;              
## [39] &quot;LightSource&quot;                &quot;Flash&quot;                     
## [41] &quot;FocalLength&quot;                &quot;Warning&quot;                   
## [43] &quot;UserComment&quot;                &quot;FlashpixVersion&quot;           
## [45] &quot;ColorSpace&quot;                 &quot;ExifImageWidth&quot;            
## [47] &quot;ExifImageHeight&quot;            &quot;InteropIndex&quot;              
## [49] &quot;InteropVersion&quot;             &quot;FileSource&quot;                
## [51] &quot;SceneType&quot;                  &quot;ExposureMode&quot;              
## [53] &quot;WhiteBalance&quot;               &quot;DigitalZoomRatio&quot;          
## [55] &quot;FocalLengthIn35mmFormat&quot;    &quot;SceneCaptureType&quot;          
## [57] &quot;Sharpness&quot;                  &quot;Compression&quot;               
## [59] &quot;ThumbnailOffset&quot;            &quot;ThumbnailLength&quot;           
## [61] &quot;MPFVersion&quot;                 &quot;NumberOfImages&quot;            
## [63] &quot;MPImageFlags&quot;               &quot;MPImageFormat&quot;             
## [65] &quot;MPImageType&quot;                &quot;MPImageLength&quot;             
## [67] &quot;MPImageStart&quot;               &quot;DependentImage1EntryNumber&quot;
## [69] &quot;DependentImage2EntryNumber&quot; &quot;ImageWidth&quot;                
## [71] &quot;ImageHeight&quot;                &quot;EncodingProcess&quot;           
## [73] &quot;BitsPerSample&quot;              &quot;ColorComponents&quot;           
## [75] &quot;YCbCrSubSampling&quot;           &quot;Aperture&quot;                  
## [77] &quot;ImageSize&quot;                  &quot;Megapixels&quot;                
## [79] &quot;ShutterSpeed&quot;               &quot;ThumbnailImage&quot;            
## [81] &quot;PreviewImage&quot;               &quot;FocalLength35efl&quot;          
## [83] &quot;LightValue&quot;</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1"></a><span class="co"># Extract timestamp and add it to our &quot;info&quot; table</span></span>
<span id="cb28-2"><a href="#cb28-2"></a>info<span class="op">$</span>Timestamp      &lt;-<span class="st"> </span><span class="kw">as.POSIXct</span>(meta<span class="op">$</span>CreateDate, <span class="dt">format =</span> <span class="st">&quot;%Y:%m:%d %H:%M:%S&quot;</span>)</span>
<span id="cb28-3"><a href="#cb28-3"></a>info<span class="op">$</span>TimestampRound &lt;-<span class="st"> </span><span class="kw">round</span>(info<span class="op">$</span>Timestamp, <span class="st">&quot;hour&quot;</span>)</span>
<span id="cb28-4"><a href="#cb28-4"></a></span>
<span id="cb28-5"><a href="#cb28-5"></a><span class="co"># Identify number of detections depending on the time of the day</span></span>
<span id="cb28-6"><a href="#cb28-6"></a>info <span class="op">%&gt;%</span></span>
<span id="cb28-7"><a href="#cb28-7"></a><span class="st">  </span><span class="kw">subset</span>(CategoryName <span class="op">==</span><span class="st"> &quot;animal&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb28-8"><a href="#cb28-8"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">TimeOfDay =</span> <span class="kw">ifelse</span>(<span class="kw">hour</span>(TimestampRound) <span class="op">%in%</span><span class="st"> </span><span class="dv">6</span><span class="op">:</span><span class="dv">22</span>, <span class="st">&quot;Day&quot;</span>, <span class="st">&quot;Night&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb28-9"><a href="#cb28-9"></a><span class="st">  </span><span class="kw">count</span>(TimeOfDay)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   TimeOfDay     n
## * &lt;chr&gt;     &lt;int&gt;
## 1 Day           1
## 2 Night         7</code></pre>
<p>But back to the question of when we detected most animals. Here, it seems that
only one of the eight detected animals appeared during the day. This is not
really surprising, as I have rarely seen other animals than our cats during the
day. Despite the useful information shown in the generated dataframe, you will
often also want to visualize the detections. For this, we’ll need to load the
respective image into R, draw a bounding box around the detected object and plot
everything. We can write a function that allows us to automate these tasks:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1"></a><span class="co"># Function to plot the i-th image with bounding box around the detection</span></span>
<span id="cb30-2"><a href="#cb30-2"></a>showDetection &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">i =</span> <span class="ot">NULL</span>){</span>
<span id="cb30-3"><a href="#cb30-3"></a></span>
<span id="cb30-4"><a href="#cb30-4"></a>  <span class="co"># Load ith image</span></span>
<span id="cb30-5"><a href="#cb30-5"></a>  img  &lt;-<span class="st"> </span><span class="kw">image_read</span>(info<span class="op">$</span>images[i])</span>
<span id="cb30-6"><a href="#cb30-6"></a>  dims &lt;-<span class="st"> </span><span class="kw">image_info</span>(img)</span>
<span id="cb30-7"><a href="#cb30-7"></a></span>
<span id="cb30-8"><a href="#cb30-8"></a>  <span class="co"># Plot</span></span>
<span id="cb30-9"><a href="#cb30-9"></a>  img &lt;-<span class="st"> </span><span class="kw">image_draw</span>(img)</span>
<span id="cb30-10"><a href="#cb30-10"></a></span>
<span id="cb30-11"><a href="#cb30-11"></a>  <span class="co"># Add bounding box around the detection (color depending on detected category)</span></span>
<span id="cb30-12"><a href="#cb30-12"></a>  <span class="kw">rect</span>(</span>
<span id="cb30-13"><a href="#cb30-13"></a>      <span class="dt">xleft   =</span> info<span class="op">$</span>x_left[i] <span class="op">*</span><span class="st"> </span>dims<span class="op">$</span>width</span>
<span id="cb30-14"><a href="#cb30-14"></a>    , <span class="dt">xright  =</span> (info<span class="op">$</span>x_left[i] <span class="op">+</span><span class="st"> </span>info<span class="op">$</span>x_width[i]) <span class="op">*</span><span class="st"> </span>dims<span class="op">$</span>width</span>
<span id="cb30-15"><a href="#cb30-15"></a>    , <span class="dt">ytop    =</span> info<span class="op">$</span>y_top[i] <span class="op">*</span><span class="st"> </span>dims<span class="op">$</span>height</span>
<span id="cb30-16"><a href="#cb30-16"></a>    , <span class="dt">ybottom =</span> (info<span class="op">$</span>y_top[i] <span class="op">+</span><span class="st"> </span>info<span class="op">$</span>y_height[i]) <span class="op">*</span><span class="st"> </span>dims<span class="op">$</span>height</span>
<span id="cb30-17"><a href="#cb30-17"></a>    , <span class="dt">border  =</span> <span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;yellow&quot;</span>, <span class="st">&quot;green&quot;</span>)[<span class="kw">as.numeric</span>(info<span class="op">$</span>category[i])]</span>
<span id="cb30-18"><a href="#cb30-18"></a>    , <span class="dt">lwd     =</span> <span class="dv">10</span></span>
<span id="cb30-19"><a href="#cb30-19"></a>  )</span>
<span id="cb30-20"><a href="#cb30-20"></a></span>
<span id="cb30-21"><a href="#cb30-21"></a>  <span class="co"># Add a text label indicating the detected class (note that we ensure that the</span></span>
<span id="cb30-22"><a href="#cb30-22"></a>  <span class="co"># label does not leave the image border on the y-axis).</span></span>
<span id="cb30-23"><a href="#cb30-23"></a>  <span class="kw">text</span>(</span>
<span id="cb30-24"><a href="#cb30-24"></a>      <span class="dt">x      =</span> info<span class="op">$</span>x_left[i] <span class="op">*</span><span class="st"> </span>dims<span class="op">$</span>width</span>
<span id="cb30-25"><a href="#cb30-25"></a>    , <span class="dt">y      =</span> <span class="kw">max</span>(info<span class="op">$</span>y_top[i], <span class="fl">0.05</span>) <span class="op">*</span><span class="st"> </span>dims<span class="op">$</span>height</span>
<span id="cb30-26"><a href="#cb30-26"></a>    , <span class="dt">labels =</span> <span class="kw">paste</span>(info<span class="op">$</span>CategoryName[i], info<span class="op">$</span>confidence[i])</span>
<span id="cb30-27"><a href="#cb30-27"></a>    , <span class="dt">cex    =</span> <span class="dv">5</span></span>
<span id="cb30-28"><a href="#cb30-28"></a>    , <span class="dt">col    =</span> <span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;yellow&quot;</span>, <span class="st">&quot;green&quot;</span>)[<span class="kw">as.numeric</span>(info<span class="op">$</span>category[i])]</span>
<span id="cb30-29"><a href="#cb30-29"></a>    , <span class="dt">adj    =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb30-30"><a href="#cb30-30"></a>  )</span>
<span id="cb30-31"><a href="#cb30-31"></a></span>
<span id="cb30-32"><a href="#cb30-32"></a>  <span class="co"># Add text indicating the image name</span></span>
<span id="cb30-33"><a href="#cb30-33"></a>  <span class="kw">text</span>(</span>
<span id="cb30-34"><a href="#cb30-34"></a>      <span class="fl">0.5</span> <span class="op">*</span><span class="st"> </span>dims<span class="op">$</span>width</span>
<span id="cb30-35"><a href="#cb30-35"></a>    , <span class="fl">0.95</span> <span class="op">*</span><span class="st"> </span>dims<span class="op">$</span>height</span>
<span id="cb30-36"><a href="#cb30-36"></a>    , <span class="kw">basename</span>(info<span class="op">$</span>images[i])</span>
<span id="cb30-37"><a href="#cb30-37"></a>    , <span class="dt">cex =</span> <span class="dv">5</span></span>
<span id="cb30-38"><a href="#cb30-38"></a>    , <span class="dt">col =</span> <span class="st">&quot;white&quot;</span></span>
<span id="cb30-39"><a href="#cb30-39"></a>    , <span class="dt">pos =</span> <span class="dv">3</span></span>
<span id="cb30-40"><a href="#cb30-40"></a>  )</span>
<span id="cb30-41"><a href="#cb30-41"></a>  <span class="kw">dev.off</span>()</span>
<span id="cb30-42"><a href="#cb30-42"></a>  <span class="kw">plot</span>(img)</span>
<span id="cb30-43"><a href="#cb30-43"></a></span>
<span id="cb30-44"><a href="#cb30-44"></a>}</span>
<span id="cb30-45"><a href="#cb30-45"></a></span>
<span id="cb30-46"><a href="#cb30-46"></a><span class="co"># Let&#39;s try it on some example images</span></span>
<span id="cb30-47"><a href="#cb30-47"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">2</span>), <span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>))</span>
<span id="cb30-48"><a href="#cb30-48"></a>plots &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="cf">function</span>(i){<span class="kw">showDetection</span>(i)})</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-25"></span>
<img src="/post/2021-04-15-megadetector_files/figure-html/unnamed-chunk-25-1.png" alt="Some example detections on cameratrap images. Differently colored bounding boxes represent the different categories. The MegaDetector is able to distinguish animals, humans (person), and vehicles. As you can see on the image on the lower right, the detector even detects animals that are not fully within the picture!" width="100%" />
<p class="caption">
Figure 3: Some example detections on cameratrap images. Differently colored bounding boxes represent the different categories. The MegaDetector is able to distinguish animals, humans (person), and vehicles. As you can see on the image on the lower right, the detector even detects animals that are not fully within the picture!
</p>
</div>
<p>Cool. It seems like the MegaDetector did a really nice job on our example
images! Obviously the <em>MegaDetector</em> is not perfect and there will always be
some misclassifications. Nevertheless, I am often very impressed by the
MegaDetector’s ability to identify animals, even on low-light black and white
images. It has happened to me multiple times that I skimmed through images and
didn’t realize that an animal was lurking somewhere in the background, yet the
MegaDetector picked it up perfectly! Nevertheless, if you’re using the
MegaDetector for scientific purposes, definitely validate its output against
some ground-truthed data ;)</p>
</div>
<div id="summary" class="section level1">
<h1>Summary</h1>
<p>Let’s summarize what we have learned in this blog post. We have explored how we
can use the <em>MegaDetector</em> to easily identify animals on cameratrap images. We
have also learned how we can import the .json output file into R to produce
neat-looking images with bounding boxes around each detected animal. Overall,
the <em>MegaDetector</em> is a very powerful and fun tool that allows us to
automatically detect animals on cameratrap images.</p>
</div>
<div id="session-information" class="section level1">
<h1>Session Information</h1>
<pre><code>## R version 3.6.3 (2020-02-29)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Linux Mint 19.3
## 
## Matrix products: default
## BLAS:   /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3
## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so
## 
## locale:
##  [1] LC_CTYPE=de_CH.UTF-8       LC_NUMERIC=C              
##  [3] LC_TIME=de_CH.UTF-8        LC_COLLATE=de_CH.UTF-8    
##  [5] LC_MONETARY=de_CH.UTF-8    LC_MESSAGES=de_CH.UTF-8   
##  [7] LC_PAPER=de_CH.UTF-8       LC_NAME=C                 
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
## [11] LC_MEASUREMENT=de_CH.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] lubridate_1.7.9.2 magick_2.4.0      exifr_0.3.2       forcats_0.5.1    
##  [5] stringr_1.4.0     dplyr_1.0.3       purrr_0.3.4       readr_1.4.0      
##  [9] tidyr_1.1.2       tibble_3.1.0      ggplot2_3.3.3     tidyverse_1.3.0  
## [13] rjson_0.2.20     
## 
## loaded via a namespace (and not attached):
##  [1] tidyselect_1.1.0  xfun_0.22         haven_2.3.1       colorspace_2.0-0 
##  [5] vctrs_0.3.7       generics_0.1.0    htmltools_0.5.1.1 yaml_2.2.1       
##  [9] utf8_1.2.1        rlang_0.4.10      pillar_1.5.1      withr_2.4.2      
## [13] glue_1.4.2        DBI_1.1.1         rappdirs_0.3.3    dbplyr_2.0.0     
## [17] modelr_0.1.8      readxl_1.3.1      plyr_1.8.6        lifecycle_1.0.0  
## [21] munsell_0.5.0     blogdown_1.3      gtable_0.3.0      cellranger_1.1.0 
## [25] rvest_1.0.0       evaluate_0.14     knitr_1.32        ps_1.5.0         
## [29] fansi_0.4.2       highr_0.8         broom_0.7.3       Rcpp_1.0.7       
## [33] scales_1.1.1      backports_1.2.1   jsonlite_1.7.2    fs_1.5.0         
## [37] hms_1.0.0         digest_0.6.27     stringi_1.5.3     bookdown_0.21    
## [41] grid_3.6.3        cli_2.4.0         tools_3.6.3       magrittr_2.0.1   
## [45] crayon_1.4.1      pkgconfig_2.0.3   ellipsis_0.3.1    xml2_1.3.2       
## [49] reprex_1.0.0      assertthat_0.2.1  rmarkdown_2.7     httr_1.4.2       
## [53] rstudioapi_0.13   R6_2.5.0          compiler_3.6.3</code></pre>
</div>


                

                <hr>
                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/post/2021-03-23-elevation/" data-toggle="tooltip" data-placement="top" title="Elevation Data in R">&larr;
                            Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/post/2021-06-27-sensitivity/" data-toggle="tooltip" data-placement="top" title="Quick Sensitivity Analyses in R">Next
                            Post &rarr;</a>
                    </li>
                    
                </ul>

                
<div id="disqus-comment"></div>



            </div>
            
            <div class="
                col-lg-11 col-lg-offset-1
                col-md-10 col-md-offset-1
                sidebar-container">

                
                

                
                
            </div>
        </div>
    </div>
</article>




<script src="//yihui.org/js/math-code.js"></script>
<script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script async src="//yihui.org/js/center-img.js"></script>

<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                   
                    
                    <li>
                        <a href="mailto:daviddenishofmann@gmail.com">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    
                    <li>
                        <a href="https://twitter.com/daviddhofmann">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    

                    

		    
                    
                    
                    <li>
                        <a target="_blank" href="https://github.com/DavidDHofmann">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
		    
                    
                    
                    
                    
                    
                    
                    
                    
            
            
            
                </ul>
		<p class="copyright text-muted">
                    Copyright &copy; David D. Hofmann 2022
                    <br>
                    <a href="https://themes.gohugo.io/hugo-theme-cleanwhite">CleanWhite Hugo Theme</a> by <a href="https://zhaohuabing.com">Huabing</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>




<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>






<script>
    
    if($('#tag_cloud').length !== 0){
        async("/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>


<script>
    async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>






<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-200759743-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



</body>
</html>
